---
title: "Topic 10: Introduction to Inference Lab"
tutorial:
  id: "IntroInferenceLab.Topic10.AppliedStats"
  version: 1.0
output: 
  learnr::tutorial:
    progressive: TRUE
    
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(eval = FALSE)
library(dplyr)
library(ggplot2)
library(learnr)
library(gradethis)

load("www/ames.RData")
set.seed(241)

area <- ames$Gr.Liv.Area
price <- ames$SalePrice

samp <- sample(area, 60)

plot_ci <- function(lo, hi, m) {
  par(mar=c(2, 1, 1, 1), mgp=c(2.7, 0.7, 0))
  k <- length(lo)
  ci.max <- max(rowSums(matrix(c(-1*lo,hi),ncol=2)))
  
  xR <- m + ci.max*c(-1, 1)
  yR <- c(0, 41*k/40)
  
  plot(xR, yR, type='n', xlab='', ylab='', axes=FALSE)
  abline(v=m, lty=2, col='#00000088')
  axis(1, at=m, paste("mu = ",round(m,4)), cex.axis=1.15)
  #axis(2)
  for(i in 1:k){
    x <- mean(c(hi[i],lo[i]))
    ci <- c(lo[i],hi[i])
    if((m < hi[i] & m > lo[i])==FALSE){
      col <- "#F05133"
      points(x, i, cex=1.4, col=col)
      #		  points(x, i, pch=20, cex=1.2, col=col)
      lines(ci, rep(i, 2), col=col, lwd=5)
    } else{
      col <- 1
      points(x, i, pch=20, cex=1.2, col=col)
      lines(ci, rep(i, 2), col=col)
    }
  }
}


tutorial_options(exercise.timelimit = 60, exercise.checker = gradethis::grade_learnr)

#knitr::opts_chunk$set(eval = FALSE)
```

## Intro to Inference Lab

In this workbook, we investigate the ways in which the statistics from a random sample of data can serve as point estimates for population parameters. This workbook builds off of the content from Topic 9, where we were exposed to the *Sampling Distribution* and the *Central Limit Theorem*. Here we will work to become more familiar with these two ideas and how we can use the sampling distribution to make claims about population-level data.

## The data

We consider real estate data from the city of Ames, Iowa. The details of every real estate transaction in Ames is recorded by the City Assessor's office. Our particular focus for this lab will be a dataset containing all residential home sales in Ames between 2006 and 2010. This collection represents our population of interest. While we typically don't have access to population-level data, this will allow us to see the Central Limit Theorem in action and to see how close our estimates come to the true population means.

###

Again, in this lab we would like to learn about these home sales by taking smaller samples from the full population. We'll see how well our small samples estimate the population parameters. The data has been loaded for you in a dataset called `ames`.

###

Use the code block below to answer some basic questions about the `ames` dataset.
```{r explore-ames, exercise = TRUE}

```

```{r explore-ames-questions, echo = FALSE}
quiz(
  question_radio(
    "What does each observation in the `ames` dataset represent?",
    answer("The sale of a home in Ames, Iowa during the time period 2006 to 2010.", correct = TRUE),
    answer("A house in Ames, Iowa"),
    answer("A person"),
    answer("A house listed for sale in Ames, Iowa"),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "How many observations are there in the `ames` dataset?",
    answer("2,930", correct = TRUE),
    answer("1"),
    answer("82"),
    answer("2,006"),
    answer("It is impossible to tell."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
   "How many variables are there in the `ames` dataset?",
    answer("2,930"),
    answer("1"),
    answer("82", correct = TRUE),
    answer("2,006"),
    answer("It is impossible to tell."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ) 
)
```

###

We see that there are quite a few variables in the data set, enough to do a very in-depth analysis. For this lab, we'll restrict our attention to just two of the variables: the above ground living area of the house in square feet (`Gr.Liv.Area`) and the sale price (`SalePrice`).  To save some effort throughout the lab, we'll create two variables with short names that represent these two variables. The code block below is pre-set to define the `area` vector -- add a second line which creates the `price` vector.
```{r assign, exercise = TRUE}
area <- ames$Gr.Liv.Area

```

```{r assign-solution}
area <- ames$Gr.Liv.Area
price <- ames$SalePrice
```

```{r assign-check}
grade_code()
```

## Initial Exploration

Let's look at the distributions of price and area in our population of home sales by calculating a few summary statistics and making a histogram. Start by using the code block below to find the mean and median for `price` and `area`. Use your results to answer the questions that follow.

```{r eda-sandbox, exercise = TRUE}

```

```{r eda-questions, echo = FALSE}
quiz(
  question_radio(
    "Which of the following is the `mean` of the `SalePrice` variable?",
    answer("$180,796.10", correct = TRUE),
    answer("$200,000"),
    answer("$160,000"),
    answer("167,842.47"),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Which of the following is the `median` of the `SalePrice` variable?",
    answer("$180,796.10"),
    answer("$200,000"),
    answer("$160,000", correct = TRUE),
    answer("167,842.47"),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "What does this tell you about the distribution of `SalePrice`?",
    answer("The `SalePrice` variable is skewed right.", correct = TRUE),
    answer("The `SalePrice` variable is skewed left."),
    answer("The `SalePrice` variable is bimodal."),
    answer("The `SalePrice` variable is symmetric."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Which of the following is the `mean` of the `area` variable?",
    answer("1,442 sqft."),
    answer("1,499.69 sqft.", correct = TRUE),
    answer("1,458.42 sqft."),
    answer("1,462.5 sqft."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Which of the following is the `median` of the `area` variable?",
    answer("1,442 sqft.", correct = TRUE),
    answer("1,499.69 sqft."),
    answer("1,458.42 sqft."),
    answer("1,462.5 sqft."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "What does this tell you about the distribution of `area`?",
    answer("The `area` variable is skewed right.", correct = TRUE),
    answer("The `area` variable is skewed left."),
    answer("The `area` variable is bimodal."),
    answer("The `area` variable is symmetric."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```

###

Use the code block below to verify your answers about the shape of the distributions from the previous questions. The code to produce the histogram and boxplot for `area` is already present. Add the code necessary to produce a histogram and boxplot for `price`. Are you able to see the skew in the distributions?
```{r plot-area-price-dists, exercise = TRUE, message = FALSE, warning = FALSE, results = FALSE, fig.width= 4, fig.height= 4}
ggplot() + geom_histogram(mapping = aes(x = area)) + ylab("Count") + xlab("Size (Sq ft)") + ggtitle("Histogram of Home Size")
ggplot() + geom_boxplot(mapping = aes(y = area)) + ylab("Size (Sq ft)") + ggtitle("Boxplot of Home Sizes") + coord_flip()
```

## Taking samples

In this lab we have access to the entire population, but this is rarely the case in real life.  Gathering information on an entire population is often extremely costly or impossible.  Because of this, we usually take a sample of the population and use that to understand the properties of the population.

###

If we were interested in estimating the mean living area in Ames based on a sample, we can use the following command to survey the population. Try running the code in the cell below a few times. What happens?
```{r samp1, exercise = TRUE}
samp1 <- sample(area, 50) #takes a sample
samp1 #print out the sample
```

###

This command collects a simple random sample of size 50 from the vector `area`, which is assigned to `samp1`. This is like going into the City Assessor's database and pulling up the files on 50 random home sales. Working with these 50 files would be considerably simpler than working with all 2,930 home sales.

Run the code block below to produce a plot of the `area` variable including all of the observations in the population (left) and a plot of only those houses contained in our sample (right). Describe the distribution of this sample. How does it compare to the distribution of the population?
```{r plot-dist-sampl, exercise = TRUE, message = FALSE, warning = FALSE, fig.width = 4, fig.height = 4}
#Take a sample
samp <- sample(area, 50)

#Plot a histogram of the entire population of home areas
ggplot() + 
  geom_histogram(mapping = aes(x = area)) + 
  labs(x = "Living Area (sqft)", y = "Count", title = "Population")

#Add the code to plot a histogram of the sample areas
ggplot() + 
  geom_histogram(mapping = aes(x = samp)) + 
  labs(x = "Living Area (sqft)", y = "Count", title = "Sample")
```

###

If we're interested in estimating the average living area of homes in Ames using the sample, our best single guess is the sample mean. Run the code block below and use the result to answer the question that follows.
```{r mean-samp1, exercise = TRUE}
samp <- sample(area, 50)
mean(samp)
```

```{r interp-point-est, echo = FALSE}
question_radio(
  "Which of the following is true?",
  answer("The sample mean is an estimate for the true population mean.", correct = TRUE),
  answer("The sample mean is the true population mean."),
  answer("We are unable to say anything about the relationship between the sample mean and population mean."),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
```

###

Depending on which 50 homes you selected, your estimate could be a bit above or a bit below the true population mean of 1499.69 square feet. In general, though, the sample mean turns out to be a pretty good estimate of the average living area, and we were able to get it by sampling less than 3% of the population.

###

Use the code block below to take a second sample, also of size 50, and call it `samp2`. How does the mean of `samp2` compare with the mean of `samp1`? 
```{r second-sample, exercise = TRUE}

```

```{r size-of-samples, echo = FALSE}
question_radio(
  "If you took a sample of size 50, a sample of size 100, and a sample of size 200, which sample would you expect to result in the most accurate estimate of the population mean?",
  answer("Sample of 50"),
  answer("Sample of 100"),
  answer("Sample of 200", correct = TRUE),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
```

## Constructing a sampling distribution

###

Not surprisingly, every time we take another random sample, we get a different sample mean.  It's useful to get a sense of just how much variability we should expect when estimating the population mean this way. The distribution of sample means, called the *sampling distribution*, can help us understand this variability. In this lab, because we have access to the population, we can build up the sampling distribution for the sample mean by repeating the above steps many times. The code below generates 5,000 samples of size 50 and computes (and stores) the sample mean of each. Run the code to see the distribution of sample means.
```{r loop, exercise = TRUE}
sample_means50 <- rep(NA, 5000)

for(i in 1:5000){
   samp <- sample(area, 50)
   sample_means50[i] <- mean(samp)
   }

ggplot() + 
  geom_histogram(mapping = aes(x = sample_means50)) + 
  labs(x = "Avg Living Area (sqft)", 
       y = "Count", 
       title = "Sampling Distribution of Sample Means (n = 50)")
```

###

If you would like to adjust the bin width of your histogram to show a different level of detail, you can do so by changing the `bins` argument. Notice the extra `bins` argument in the call to `geom_histogram()` below. Run the code to see the difference in the two plots.

```{r hist-breaks, exercise = TRUE}
sample_means50 <- rep(NA, 5000)

for(i in 1:5000){
   samp <- sample(area, 50)
   sample_means50[i] <- mean(samp)
   }

ggplot() + 
  geom_histogram(mapping = aes(x = sample_means50), bins = 8) + 
  labs(x = "Avg Living Area (sqft)", 
       y = "Count", 
       title = "Sampling Distribution of Sample Means (n = 50)")
```

###

We used R to take 5,000 samples of size 50 from the population, calculate the mean of each sample, and store each result in a vector called `sample_means50`. Don't worry if you don't understand the code yet -- we'll review it shortly. But first, answer a couple of questions.

```{r samp-means-50-questions, echo = FALSE}
quiz(
  question_radio(
    "How many elements are there in `sample_means50`?",
    answer("50"),
    answer("82"),
    answer("2,930"),
    answer("5,000", correct = TRUE),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Where is the sampling distribution centered? That is, what is the mean of the distribution of sample means?",
    answer("Approximately 1,500 sqft", correct = TRUE),
    answer("Approximately 2,930 sqft"),
    answer("Approximately 1,250 sqft"),
    answer("Approximately 1,600 sqft"),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Would you expect the distribution to change if we instead collected 50,000 sample means instead of 5,000?",
    answer("No. We would have more sample means, but the shape of the distribution would not likely change much.", correct = TRUE),
    answer("Yes. The distribution would be more narrow."),
    answer("Yes. The distribution may change drastically since this is an entire new set of samples and will contain so many more samples."),
    answer("No. The distribution will be exactly the same."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```

## Interlude: The `for` loop

Let's take a break from the statistics for a moment to understand the code you used to generate all of those sample means and build the sampling distribution. 

###

You have just run your first `for` loop, a cornerstone of computer programming.  The idea behind the for loop is *iteration*: it allows you to execute code as many times as you want without having to type out every iteration. In the case above, we wanted to iterate the two lines of code inside the curly braces that take a random sample of size 50 from `area` then save the mean of that sample into the `sample_means50` vector.  Without the `for` loop, this would be painful:

###

The code below is what would need to be written in order to fill in the first four entries of `sample_means50` -- you would only need to copy and paste the code 4,996 more times to fill in the entire vector!
```{r loop-long, eval=FALSE}
sample_means50 <- rep(NA, 5000)

samp <- sample(area, 50)
sample_means50[1] <- mean(samp)

samp <- sample(area, 50)
sample_means50[2] <- mean(samp)

samp <- sample(area, 50)
sample_means50[3] <- mean(samp)

samp <- sample(area, 50)
sample_means50[4] <- mean(samp)
```

###

With the for loop, these thousands of lines of code are compressed into a handful of lines. Here's a simple loop -- read the code and guess what will happen. Once you've made a guess, run the code and see if you were right.
```{r simple-loop, exercise = TRUE}
total <- 0

for(i in 1:10){
  total <- total + i
  print(total)
  }
```

###

Now, back to the original code:
```{r original-loop}
sample_means50 <- rep(NA, 5000)

for(i in 1:5000){
   samp <- sample(area, 50)
   sample_means50[i] <- mean(samp)
   }
```

Let's consider this code line by line to figure out what it does. 

+ In the first line we *initialized a vector*.  In this case, we created a vector of 5,000 `NA` entries called `sample_means50`.  This vector will will store values generated within the `for` loop.
+ The second line calls the `for` loop itself.  The syntax can be loosely read as, "for every integer `i` from 1 to 5000, run the following lines of code". You can think of `i` as the counter that keeps track of which loop you're on. Therefore, more precisely, the loop will run once when `i = 1`, then once when `i = 2`, and so on up to `i = 5000`.
+ The body of the `for` loop is the part inside the curly braces, and this set of code is run for each value of `i`.  Here, on every iterate, we take a random sample of size 50 from `area`, take its mean, and store it as the $i^{th}$ element of `sample_means50`.

###

The `for` loop allows us to not just run the code 5,000 times, but to neatly package the results, element by element, into the empty vector that we initialized at the outset. 

###

To make sure you understand what you've done in this loop, try building and running a smaller version in the code block below. Initialize a vector of 100 zeros called `sample_means_small`.  Run a loop that takes a sample of size 50 from `area` and stores the sample mean in `sample_means_small`, but only iterate from 1 to 100.  Print the output to your screen by including a line `sample_means_small` after the loop concludes. 
```{r small-loop, exercise = TRUE}

```

```{r small-loop-solution}
sample_means_small <- rep(0, 100)

for(i in 1:100){
   samp <- sample(area, 50)
   sample_means_small[i] <- mean(samp)
}

sample_means_small
```

```{r small-loop-check}
grade_code()
```

###

Answer the following questions about `sample_means_small`.
```{r sample-means-small-question, echo = FALSE}
quiz(
  question_radio(
    "How many elements are there in `sample_means_small`?",
    answer("10"),
    answer("50"),
    answer("100", correct = TRUE),
    answer("2,930"),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "What does each element of `sample_means_small` represent?",
    answer("The living area of a house in square feet."),
    answer("The average living area of a random sample of 50 houses in square feet.", correct = TRUE),
    answer("The average living area of a random sample of 100 houses in square feet."),
    answer("The average living area of a random sample of 5,000 houses in square feet."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```

## Sample size and the sampling distribution

Mechanics aside, let's return to the reason we used a `for` loop: to compute a sampling distribution, specifically, this one.

```{r hist-sample-means-50-setup}
sample_means50 <- rep(NA, 5000)

for(i in 1:5000){
  sample_means50[i] <- mean(sample(area, 50))
}
```

```{r hist-sample-means-50, exercise = TRUE}
ggplot() + geom_histogram(mapping = aes(x = sample_means50)) + 
  labs(x = "Avg Living Area (sqft)", 
       y = "Count", 
       title = "Sampling Distribution of Sample Means (n = 50)")
```

###

The sampling distribution that we computed tells us much about estimating the average living area of homes in Ames. Because the sample mean is an unbiased estimator, the sampling distribution is centered at the true average living area of the the population, and the spread of the distribution indicates how much variability is induced by sampling only 50 home sales.

###

To get a sense of the effect that sample size has on our distribution, build up two more sampling distributions: one based on a sample size of 10 and another based on a sample size of 100. Call them `sample_means10` and `sample_means100` respectively. Use the code block below to adapt the code used to create `sample_means50` to create these two new objects. The code to create `sample_means50` is commented out in the code block below for reference.
```{r samp10-samp100, exercise = TRUE}
#sample_means50 <- rep(NA, 5000)

#for(i in 1:5000){
#   samp <- sample(area, 50)
#   sample_means50[i] <- mean(samp)
#   }
```

###

Now that you've created the two new sampling distributions we can see the effect that different sample sizes have on the sampling distribution, by plotting the three distributions on top of one another. I've combined the simulated sample means data into a single data frame for convenient plotting. Run the code block below to create the plots.

```{r plot-samp-dists-setup}
sample_means50 <- rep(NA, 5000)
sample_means10 <- rep(NA, 5000)
sample_means100 <- rep(NA, 5000)

for(i in 1:5000){
   samp10 <- sample(area, 10)
   sample_means10[i] <- mean(samp10)
   samp50 <- sample(area, 50)
   sample_means50[i] <- mean(samp50)
   samp100 <- sample(area, 100)
   sample_means100[i] <- mean(samp100)
}

df10 <- data.frame("SampDist" = rep("sample_means10", length(sample_means10)), "SampleMean" = sample_means10)
df50 <- data.frame("SampDist" = rep("sample_means50", length(sample_means50)), "SampleMean" = sample_means50)
df100 <- data.frame("SampDist" = rep("sample_means100", length(sample_means100)), "SampleMean" = sample_means100)

sample_means <- bind_rows(df10, df50, df100)
sample_means$SampDist <- factor(sample_means$SampDist, levels = c("sample_means10", "sample_means50", "sample_means100"), ordered = TRUE)
```

```{r plot-samp-dists, exercise = TRUE}
ggplot(data = sample_means) + 
  geom_histogram(mapping = aes(x = SampleMean)) + 
  facet_wrap(~ SampDist, nrow = 3) +
  labs(x = "Avg Living Area (sqft)", y = "count", title = "Sampling Distributions (n = 10, 50, 100)")
```

###

Remember that `facet_wrap()` allows you to create a separate plot for each level of a categorical variable.

```{r plot-samps-questions, echo = FALSE}
quiz(
  question_radio(
    "When the sample size is larger, what happens to the center of the sampling distribution?",
    answer("The center stays near the population mean (about 1500 square feet).", correct = TRUE),
    answer("The center bounces around uncontrollably!"),
    answer("The center stayed near the population mean, but if we ran this a second time the results could be quite different."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "What happens to the spread of the sampling distribution as the sample size increases?",
    answer("The larger the sample size, the wider the sampling distribution"),
    answer("The larger the sample size, the more narrow the sampling distribution", correct = TRUE),
    answer("The sample size and spread of the sampling distribution are independent"),
    answer("Larger sample sizes resulted in a more narrow spread this time, but if we built new sampling distributions we may not reproduce this."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```

## Confidence intervals

Based on a sample, what can we infer about the population? Based only on a single sample, the best estimate of the average living area of houses sold in Ames would be the sample mean, usually denoted as $\bar{x}$ (here we've been calling it `sample_mean`). That serves as a good *point estimate* but it would be useful to also communicate how uncertain we are of that estimate. This can be captured by using a *confidence interval*.

###

We can calculate a 95% confidence interval for a sample mean by adding and subtracting 1.96 standard errors to the point estimate (See Section 4.2.3 of our book if you are unfamiliar with this formula). If you remember our discussion on the *Empirical Rule*, then you recall that we said approximately 95% of observations fall within two standard deviations (standard errors) of the mean -- the 1.96 here is a more accurate value. Essentially the 1.96 comes from the idea that a 95% confidence interval has an error of 5%, which is distributed equally to the two tails of a normal distribution. 

Use the code block below to take a single sample of size 60 of areas from houses in Ames. Call it `samp`.
```{r samp60, exercise = TRUE}

```

```{r samp60-solution}
samp <- sample(area, 60)
```

```{r samp60-check}
grade_code()
```

###

Run the code below to construct the confidence interval.
```{r ci, eval=FALSE, exercise = TRUE}
sample_mean <- mean(samp)
se <- sd(samp) / sqrt(60)
lower <- sample_mean - 1.96 * se
upper <- sample_mean + 1.96 * se
c(lower, upper)
```

###

This is an important inference that we've just made: even though we don't know what the full population looks like, we're 95% confident that the true average size of houses in Ames lies between the values *lower* and *upper*. There are a few conditions that must be met for this interval to be valid.

```{r ci-assumption, echo = FALSE}
quiz(
  question_checkbox(
    "For the confidence interval to be valid, the sample mean must be normally 
distributed and have standard error $s / \\sqrt{n}$. What conditions must be 
met for this to be true? (check all the requirements)",
    answer("The population must be normally distributed"),
    answer("The sample size must be large enough to overcome any skew in the population (usually at least 30 for moderate skew)", correct = TRUE),
    answer("The sample taken must be random and representative of the population.", correct = TRUE),
    answer("The confidence interval must contain the true population mean."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Which of the following is the correct interpretation of the 95% confidence interval?",
    answer("We are 95% confident that the true population mean square footage of living area for houses sold in Ames, Iowa between 2006 and 2010 is between the lower and upper bound.", correct = TRUE),
    answer("There is a 95% chance that the true population mean square footage of living area for houses sold in Ames, Iowa between 2006 and 2010 is between the lower and upper bound."),
    answer("We are 95% confident that the sample mean square footage of living area for houses sold in Ames, Iowa between 2006 and 2010 is between the lower and upper bound."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```
  
###

In this case we have the luxury of knowing the true population mean since we have data on the entire population. As a reminder, we calculated it earlier -- it is `r mean(area)` square feet (which we can calculate with the `mean()` function).

###

Every time you run the code to build `samp60` and construct the confidence interval you will get a slightly different confidence interval. What proportion of those intervals would you expect to capture the true population mean?

```{r prop-ci-contain-param, echo = FALSE}
question_radio(
  "If you built these confidence intervals over and over, about what proportion of the intervals do you expect to contain the true population mean?",
  answer("About 95%", correct = TRUE),
  answer("About 90%"),
  answer("100%"),
  answer("Around 50%"),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
```

####

Using $\tt{R}$, we're going to recreate many samples to learn more about how sample means and confidence intervals vary from one sample to another.

Here is the rough outline:

+   Obtain a random sample.
+   Calculate and store the sample's mean and standard deviation.
+   Repeat steps (1) and (2) fifty times.
+   Use these stored statistics to calculate many confidence intervals.

###

Read the code below -- does it make sense to you? What do you think the result will be? You've used everything in the code block below during this workbook, except for the custom `plot_ci()` function. Once you think you know what will result, run the code block and see if you were right.
```{r lots-of-ci, exercise = TRUE}
samp_mean <- rep(NA, 50)
samp_sd <- rep(NA, 50)
n <- 60

for(i in 1:50){
  samp <- sample(area, n) # obtain a sample of size n = 60 from the population
  samp_mean[i] <- mean(samp)    # save sample mean in ith element of samp_mean
  samp_sd[i] <- sd(samp)        # save sample sd in ith element of samp_sd
}

lower_vector <- samp_mean - 1.96 * samp_sd / sqrt(n) 
upper_vector <- samp_mean + 1.96 * samp_sd / sqrt(n)

plot_ci(lower_vector, upper_vector, mean(area))
```

###

Run the code above multiple times. Do your results change? What do the red highlighted intervals indicate? About how many red intervals are you observing on average? What happens if you change the sample sizes taken? What conclusions can you draw about the relationship between sample size and the confidence intervals?

###

Good work through this activity. I hope it has made the Central Limit Theorem and Sampling Distributions a bit more intuitive to you. We'll do more with confidence intervals in the second half of our course. If you are interested in doing more, go back through this workbook using the `price` data.

###

<div id="license">
This is a derivative of a product of OpenIntro that is released under a [Creative Commons Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0). This lab was adapted for OpenIntro by Andrew Bray and Mine &Ccedil;etinkaya-Rundel from a lab written by Mark Hansen of UCLA Statistics.
</div>

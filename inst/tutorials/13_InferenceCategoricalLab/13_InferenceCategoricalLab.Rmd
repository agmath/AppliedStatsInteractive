---
title: "Topic 13: Inference for Categorical Data Lab"
tutorial:
  id: "InferenceCategoricalLab.Topic13.AppliedStats"
  version: 1.0
output: 
  learnr::tutorial:
    progressive: TRUE
    allow_skip: TRUE
    
runtime: shiny_prerendered
description: "In this lab, we work with survey data from a 2012 WIN-Gallup poll on the global rise of atheism. The `inference()` function from the `{statsr}` package is introduced."
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(eval = FALSE)
#library(tidyverse)
library(ggplot2)
library(dplyr)
library(learnr)
library(gradethis)
library(statsr)

tutorial_options(exercise.timelimit = 60, exercise.checker = gradethis::grade_learnr)

load("www/atheism.RData")
rm(inference)

#knitr::opts_chunk$set(eval = FALSE)
```

## Inference for Categorical Data (Lab)

###

In August of 2012, news outlets ranging from the [Washington Post](http://www.washingtonpost.com/national/on-faith/poll-shows-atheism-on-the-rise-in-the-us/2012/08/13/90020fd6-e57d-11e1-9739-eef99c5fb285_story.html){target="_blank"} to the [Huffington Post](http://www.huffingtonpost.com/2012/08/14/atheism-rise-religiosity-decline-in-america_n_1777031.html){target="_blank"} ran a story about the rise of atheism in America. The source for the story was a poll that asked people, "Irrespective of whether you attend a place of worship or not, would you say you are a religious person, not a religious person or a convinced atheist?" This type of question, which asks people to classify themselves in one way or another, is common in polling and generates categorical data. In this workbook we take a look at the atheism survey and explore what's at play when making inference about population proportions using categorical data.

###

<div id="license">
This is a derivative of a product of OpenIntro that is released under a [Creative Commons Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0){target="_blank"}. The oiginal lab was written for OpenIntro by Andrew Bray and Mine &Ccedil;etinkaya-Rundel.</div>

###

## The survey

You can find the press-release for the WIN-Gallup International poll on the Global Index of Religion and Atheism [here](www/Religiosity_and_Atheism.pdf){target=_"blank"}. Please take a moment to review the report then address the following questions.

```{r questions-report, echo = FALSE}
quiz(
  question_radio(
    "In the first paragraph, several key findings are reported. Do these percentages appear to be *sample statistics* (derived from the data sample) or *population parameters*?",
    answer("sample statistics", correct = TRUE),
    answer("population parameters"),
    answer("There is a mix of both"),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "The title of the report is *Global Index of Religiosity and Atheism*. To generalize the report's findings to the global human population, what must we assume about the sampling method?",
    answer("The sample must be random and representative of the global community", correct = TRUE),
    answer("The sample must contain at least 10% of the global population"),
    answer("The sample should include people of all religions, so samples should be taken near a diverse set of places of worship"),
    answer("The survey should be done on the phone to make sure that respondents understand the question being asked"),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Do you expect that the required assumption was satisfied? What are the implications of this?",
    answer("No. The study results can only be extended to countries and regions for which the sample data is representative.", correct = TRUE),
    answer("Yes. The study included a very large number of respondents."),
    answer("Yes. Win-Gallup is a reputable polling organization."),
    answer("No. In order to apply results to the global community the pollsters would need to conduct a census."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```

###

Turn your attention to Table 6 (pages 14 and 15) in the Religiosity and Atheism poll documentation, which reports the sample size and response percentages for all 57 countries. While this is a useful format to summarize the data, we will base our analysis on the original data set of individual responses to the survey. These original responses are loaded into this workbook for you in a data frame named `atheism`.

```{r table-v-df-code-block, exercise = TRUE}

```

```{r table-v-df, echo = FALSE}
question_radio(
  "What does each row of Table 6 correspond to? What does each row of `atheism` correspond to?",
  answer("Each row of Table 6 contains the summarized responses by country while each row of `atheism` contains the response of an individual respondent.", correct = TRUE),
  answer("Each row of both Table 6 and the `atheism` data frame contain the response of an individual respondent."),
  answer("Each row of both Table 6 and the `atheism` data frame contain the summarized responses by country."),
  answer("Each row of Table 6 contains the response of an individual respondent while each row of `atheism` contains the summarized responses by country."),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
```

###

To investigate the link between these two ways of organizing this data, take a look at the estimated proportion of atheists in the United States. Towards the bottom of Table 6, we see that this is 5%. We should be able to come to the same number using the `atheism` data.

###

Run the command in the code block below and be sure to understand what the code is doing since you'll be asked to do some similar things later in the workbook. In that code cell, we create a new dataframe called `us12` that contains only the rows in `atheism` associated with respondents to the 2012 survey from the United States. Next, we calculate the proportion of atheist responses. Does it agree with the percentage in Table 6? If not, why?

```{r us-atheism, exercise = TRUE}
us12 <- atheism %>%
  filter(nationality == "United States", 
         year == 2012)

us12 %>%
  count(response) %>%
  mutate(relative_frequency = n / sum(n))
```

## Inference on proportions

###

As you noted previously, Table 6 provides *statistics*, that is, calculations made from the sample of 51,927 people. We'd like insight into the population *parameters* instead. You answer the question, "What proportion of people *in your sample* reported being atheists?" with a sample statistic; while the question "What proportion of people *on Earth* would report being atheists?" is answered with an estimate of the parameter.

###

You'll use what you've learned about inferential tools for estimating population proportions in the previous workbook to answer questions related to the WIN-Gallup poll. Additionally, you'll explore how the value of the population proportion can impact the margin of error for a confidence interval.

###

As long as the conditions for inference are reasonably well satisfied, we can either calculate the standard error and construct the confidence interval by hand or allow the `inference()` function from the `{statsr}` package to do it for us. We note that the `inference()` function is part of the `{statsr}` package for R, which has been installed and loaded for you here.

Run the following code block to construct a confidence interval for the proportion of atheists in the US in 2012.

```{r us-atheism-ci-setup}
us12 <- atheism %>%
  filter(nationality == "United States", 
         year == 2012)
```

```{r us-atheism-ci, exercise = TRUE}
inference(y = response,
          data = us12,
          statistic = "proportion", 
          type = "ci", 
          method = "theoretical", 
          success = "atheist")
```

###

Let's pause for a moment to go through the arguments of this function. The first argument is `y`, which is the response variable that we are interested in: `response`. The next argument, `data` tells the function which data frame to look in and find the `response` column. The `statistic` argument, is the parameter we're interested in: `"proportion"` (other options are `"mean"`, or `"median"`.) Next we decide on the `type` of inference we want: a hypothesis test (`"ht"`) or a confidence interval (`"ci"`). When performing a hypothesis test, we also need to supply the `null` value and `alternative` hypothesis but we're building a confidence interval here so we omit those values -- we can optionally set the `conf_level` parameter but the default is a 95% confidence interval (`conf_level = 0.95`). The `method` parameter chooses the method of inference: `"theoretical"` or `"simulation"` based -- our course is using a theoretical framework, so we will always use that option. Finally, since the goal is to construct an interval estimate for a proportion, it's necessary to specify which level constitutes a "success"; here that is a response of `"atheist"`.

###

Although formal confidence intervals and hypothesis tests don't show up in the WINN-Gallup report, suggestions of inference appear at the bottom of page 6: "In general, the error margin for surveys of this kind is $\pm$ 3-5% at 95% confidence". We will check the validity of this claim later on.

Use the code block below to help you answer the question that follows.

```{r interp-inference-moe-code-block, exercise = TRUE}

```

```{r interp-inference-moe-code-block-hint-1}
#The margin of error is half the width of the 
#confidence interval. You might think of this 
#as the "radius" of the confidence interval.

```

```{r interp-inference-moe, echo = FALSE}
question_radio(
  "Based on the R output, what is the margin of error for the estimate of the proportion of the proportion of atheists in US in 2012?",
  answer("0.0135", correct = TRUE),
  answer("0.0499"),
  answer("0.0069", message = "Oops. The margin of error is the product of the standard error and critical value."),
  answer("0.0364"),
  answer("0.0634"),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
```

###

Using the code block below and your `inference()` function, calculate confidence intervals for the proportion of atheists in 2012 in two other countries of your choice, and report the associated margins of error. Be sure to note whether the conditions for inference are met. It will be helpful to create new data sets for each of the two countries first, and then use these data sets in the `inference()` function to construct the confidence intervals.

```{r use-inference, exercise = TRUE}

```

```{r use-inference-hint-1}
#Revisit the code cell from earlier where we 
#created the us12 data frame.

```

```{r use-inference-hint-2}
#Use similar code to obtain data from a 
#different country, year, or both!

```

```{r use-inference-hint-3}
#Use inference() to build a confidence
#interval for the proportion of atheists
#in your new data frame.

```

## How does the proportion affect the margin of error?

Imagine you've set out to survey 1000 people on two questions: are you female? and are you left-handed? Since both of these sample proportions were calculated from the same sample size, they should have the same margin of error, right? Not so fast! While the margin of error does change with sample size, it is also affected by the proportion.

###

Think back to the formula for the standard error: $SE = \sqrt{p(1-p)/n}$. This is then used in the formula for the margin of error for a 95% confidence interval: $ME = 1.96\times SE = 1.96\times\sqrt{p(1-p)/n}$. Since the population proportion $p$ is in this $ME$ formula, it should make sense that the margin of error is in some way dependent on the population proportion. We can visualize this relationship by creating a plot of $ME$ vs. $p$, which is exactly what you'll do through these next few activities.

###

The code block below is pre-populated with the code necessary to make a vector `p` that is a sequence from 0 to 1 with each number separated by 0.01. The code then creates a vector of the margin of error (`me`) associated with each of these values of `p` using the familiar approximate formula ($ME = 2 \times SE$) -- note that we could also use the critical values associated with any confidence level we would like instead of 2 -- you might try this and see what happens! Lastly, we plot the two vectors against each other to reveal their relationship.

```{r me-plot, exercise = TRUE, exercise.eval = FALSE}
n <- 1000
p <- seq(0, 1, 0.01)
me <- 2 * sqrt(p * (1 - p)/n)

ggplot() + 
  geom_point(aes(x = p, y = me)) + 
  labs(
    title = "Margin of Error and Population Proportion", 
    y = "Margin of Error", 
    x = "Population Proportion"
    )
```

###

```{r p-and-me-questions, echo = FALSE}
quiz(
  question_radio(
    "Describe the relationship between the population proportion, $p$, and margin of error.",
    answer("The margin of error is small if the population proportion is near 0 or 1 but is largest for values near 0.5", correct = TRUE),
    answer("The margin of error is larger for larger values of the population proportion."),
    answer("The margin of error is smaller for larger values of the population proportion."),
    answer("There is no meaningful relationship between the population proportion and margin of error."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_checkbox(
    "Which of the following are implications of your answer above?",
    answer("Margins of error, and therefore confidence intervals, will be widest when the population proportion to be captured is close to 0.5", correct = TRUE),
    answer("In order to estimate a population proportion to within a desired margin of error, larger sample sizes will be needed if the true population proportion is near 0.5.", correct = TRUE),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```

###

We now know that both sample size and the population parameter impact the margin of error. Often times pollsters will have requirements for the margin of error for an estimate (for example, we may be interested in estimating a President's net favorability rating to within plus or minus three percentage points). They can use these requirements, prior information, and any intuition they may have about an approximate value of the population proportion to estimate how much data they need to collect in order to satisfy their requirements on the margin of error. We can estimate required sample size using the formula below, which is just a rearrangement of the formula for margin of error ($M_E$):
$$n \geq \left(\frac{Z_{\alpha/2}}{M_E}\right)^2\cdot p\left(1 - p\right)$$
In the formula above:

+ $Z_{\alpha/2}$ is the critical value associated with the desired confidence level
+ $M_E$ is the desired margin of error
+ $p$ is an estimate for the population proportion made by using any intuition the pollster has -- if there is no viable intuition then we use $p=0.5$, a worst case scenario (as you identified earlier).

You won't use this formula right now, but you'll need it to answer one of the questions at the end of this workbook.

## Success-failure condition

The textbook emphasizes that you must always check conditions before making inference. For inference on proportions, the sample proportion can be assumed to be nearly normal if it is based upon a random sample of independent observations and if both $np \geq 10$ and $n(1 - p) \geq 10$. This rule of thumb is easy enough to follow, but it makes one wonder: what's so special about the number 10?

###

The short answer is: nothing. You could argue that we would be fine with 9 or that we really should be using 11. The "best" value for such a rule of thumb is, at least to some degree, arbitrary. However, when $np$ and $n(1-p)$ both reach 10 the sampling distribution is sufficiently normal to use confidence intervals and hypothesis tests that are based on that approximation.

###

We can investigate the interplay between $n$ and $p$ and the shape of the sampling distribution by using simulations. To start off, we simulate the process of drawing 5000 samples of size 1040 from a population with a true atheist proportion of 0.1. For each of the 5000 samples we compute $\hat{p}$ and then plot a histogram to visualize their distribution.

Use the code block below to carry out this experiment.

```{r sim-np, exercise = TRUE, exercise.eval = FALSE}
p <- 0.1
n <- 1040
p_hats <- rep(0, 5000)

for(i in 1:5000){
  samp <- sample(c("atheist", "non_atheist"), 
                 n, 
                 replace = TRUE, 
                 prob = c(p, 1-p))
  
  p_hats[i] <- sum(samp == "atheist")/n
}

ggplot() + 
  geom_histogram(aes(x = p_hats)) + 
  labs(title = "p = 0.1, n = 1040", 
       x = "Estimates for p") + 
  xlim(c(0, 0.18))
```

###

These commands build up the sampling distribution of $\hat{p}$ using the familiar `for` loop. You can read the sampling procedure for the first line of code inside the `for` loop as, "take a sample of size $n$ with replacement from the choices of atheist and non-atheist with probabilities $p$ and $1 - p$,respectively." The second line in the loop says, "calculate the proportion of atheists in this sample and record this value." The loop allows us to repeat this process 5,000 times to build an approximation of the sampling distribution.

Use the code block below to repeat the simulation we just ran but with `n = 400` and `p = 0.1`. Be sure to plot your result and compare it to your original simulation. What impact did lowering the number of observations have?

```{r p-dist-400-10, exercise = TRUE}

```

```{r p-dist-400-10-hint-1}
#Start with the code to run the original
#simulation. Change the sample size (n) 
#and the population proportion (p).

```

###

Now re-run the experiment again, but with `n = 1040` and `p = 0.02`. Again, think about the impact that a smaller population proportion has on the distribution of estimates for the population proportion.

```{r p-dist-1040-02, exercise = TRUE}

```

```{r p-dist-1040-02-hint-1}
#Again, start with the code to run the 
#original simulation. Change the sample 
#size (n) and the population proportion (p).

```

###

Re-run the experiment one last time, but with `n = 400` and `p = 0.02`. Compare each of your resulting distributions. How does this connect back to the assumptions for inference with categorical data?

```{r p-dist-400-02, exercise = TRUE}

```

```{r p-dist-400-02-hint-1}
#Same idea here. Update the sample size 
#and population proportion from the 
#original simulation.

```

###

```{r question-assumptions, echo = FALSE}
question_radio(
  "If you refer to Table 6 again in the WIN-Gallup report, you'll find that Australia has a sample proportion of 0.1 on a sample size of 1040, and that Ecuador has a sample proportion of 0.02 on 400 subjects. Let's suppose for this exercise that these point estimates are actually the truth. Then given the shape of their respective sampling distributions, do you think it is sensible to proceed with inference and report margin of errors, as the reports does?",
  answer("The report should not proceed with inference on Ecuador since the success-failure condition is not satisfied. The report can safely proceed with inference on Australia though.", correct = TRUE),
  answer("The report can proceed with inference on all countries. Since there were over 50,000 responses, the success-failure condition is satisfied."),
  answer("The report should not proceed with inference on either Ecuador or Australia, since the success-failure condition may not be satisfied for either country."),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
```

## On your own

The question of atheism was asked by WIN-Gallup International in a similar survey that was conducted in 2005. (We assume here that sample sizes have remained the same.) Table 4 on page 12 of the report summarizes survey results from 2005 and 2012 for 39 countries. Try answering the following questions on your own. The code blocks are necessary for answering some of the questions, but are not needed for all.

1. Answer the following two questions using the `inference()` function from `{statsr}`. As always, write out the hypotheses for any tests you conduct and outline the status of the conditions for inference.

  + Is there convincing evidence that Spain has seen a change in its atheism index between 2005 and 2012? *Hint:* Create new data sets for respondents from Spain in 2005 and 2012 (look back at how we created `us12` earlier in this workbook). Form confidence intervals for the true proportion of atheists in both years, and determine whether they overlap.
  + Is there convincing evidence that the United States has seen a change in its atheism index between 2005 and 2012?

```{r on-your-own-1, exercise = TRUE}

```

```{r on-your-own-1-hint-1}
#Start by defining spain to be a data frame
#containing only responses from Spain. You 
#don't need to filter on the year, since 
#2005 and 2012 are the only years with 
#observed responses.

```

```{r on-your-own-1-hint-2}
#Use the inference() function as earlier, but
#pass the year variable to the optional x 
#argument. This will create groups for year
#and inference() will automatically build a 
#confidence interval for the difference in 
#proportions of atheists between 2005 and 2012.
#You can ignore the warning about converting to 
#a factor.

```

2. If in fact there has been no change in the atheism index in any of the countries listed in Table 4, in how many of those countries would you expect to detect a change (at a significance level of 0.05) simply by chance? *Hint:* Look in the textbook index under Type 1 error.

```{r on-your-own-2, exercise = TRUE}

```

3. Suppose you're hired by the local government to estimate the proportion of residents that attend a religious service on a weekly basis. According to the guidelines, the estimate must have a margin of error no greater than 1% with 95% confidence. You have no idea what to expect for $p$. How many people would you have to sample to ensure that you are within the guidelines? *Hint:* Refer to your plot of the relationship between $p$ and margin of error. Do not use the data set to answer this question.

```{r on-your-own-3, exercise = TRUE}

```

```{r on-your-own-3-hint-1}
#Use the sample size formula for inference on 
#population proportions. That formula is on 
#the Standard Error Decision Tree and was also 
#included within this notebook.

```

```{r on-your-own-3-hint-2}
#Since you have no idea what proportion of 
#residents attend a religious service on a 
#weekly basis, use p = 0.5 as a worst-case
#estimate. This value of the population 
#proportion results in the largest possible 
#estimated sample size requirements.

```

## Submit

```{r context="server"}
learnrhash::encoder_logic(strip_output = TRUE)
```

```{r encode, echo=FALSE}
learnrhash::encoder_ui(
  ui_before = shiny::div(
    "If your instructor is asking you to submit evidence of your completed notebook using a hash code, you may generate that code below. Use the clipboard icon to ensure that you are copying the entire hash."
    )
  )
```

## Summary

Good work. I hope that this workbook has helped make inferential techniques a bit more intuitive for you. In particular, I hope that you better understand the connection between the margin of error and a confidence interval as well as the dependence of standard error on sample size and population proportion.

###

<div id="license">
This is lab a derivative of a product of OpenIntro that is released under a [Creative Commons Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0). The oiginal lab was written for OpenIntro by Andrew Bray and Mine &Ccedil;etinkaya-Rundel.</div>

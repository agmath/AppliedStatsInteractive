---
title: "Topic 9: Foundations For Inference"
tutorial:
  id: "FoundationsForInferenceLab.Topic9.AppliedStats"
  version: 1.0
output: 
  learnr::tutorial:
    progressive: TRUE
    allow_skip: TRUE
    
runtime: shiny_prerendered
description: "This notebook provides and introduction to the Central Limit Theorem. We'll see the Central Limit Theorem in action through several simulations which construct the sampling distribution. We'll have opportunities to change parameters of the population distribution and also to change the size of the samples being drawn. The goal is to discover connections between population parameters, sample size, and the resulting sampling distribution."
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(eval = FALSE)
library(dplyr)
library(ggplot2)
library(learnr)
library(gradethis)

tutorial_options(exercise.timelimit = 60, exercise.checker = gradethis::grade_learnr)

#knitr::opts_chunk$set(eval = FALSE)
```

## Foundations for Inference

In this workbook we'll begin investigating the true power of statistics -- using sample data to make accurate claims about a population (even when we don't have access to the entire population). We start by exploring the connection between a *Population Distribution* and the distribution of sample means, often called the *Sampling Distribution*. We'll do this through a series of simple, interactive code blocks which you will run and use to answer questions.

## Exploring the connection between population and sampling distributions

Start by viewing the following following video from the New York Times.

###

<center><iframe width="560" height="315" src="https://www.youtube.com/embed/jvoxEYmQHNM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></center>

###

So the video claimed that the sampling distribution can help us answer questions about the population. This is really important because, as we mentioned in our first Workbook, Census is almost always impossible. Use the code blocks below to explore the connection between the population and the sampling distribution for various different populations. Note that you do not need to understand all of the code contained in the code blocks -- you should focus, instead, on the pictures resulting each time you run the code. In general, you are invited to change the first few lines of code in each block, and you are not expected to look at the remaining code.

### A Normally Distributed Population

**Normally Distributed Population:** Work with the following code block to explore the connection between the population distribution and sampling distribution when the population follows a normal distribution. Use your explorations to answer the questions that follow.
```{r norm-pop-samp-dist, exercise = TRUE, message = FALSE, warning = FALSE, fig.width = 4, fig.height = 4}
#Define the population mean (feel free to change)
mean <- 80
#Define the population standard deviation (feel free to change)
sd <- 5
#Define the sample size (feel free to change)
size <- 1
#Define the number of samples to be taken (feel free to change)
numSamps <- 10000

#######################################
##Function to take samples, compute
##means and build sampling distribution
##Please don't edit.
#######################################
drawN <- function(n, times){
  vals <- rep(NA, times)
  for(i in 1:times){
    draws <- rnorm(n, mean, sd)
    vals[i] <- mean(draws)
  }
  vals
}
#######################################
##Use the function we defined to take the samples
trials <- drawN(size, numSamps)

#Plot the population distribution and histogram of sample means
ggplot() + 
  geom_histogram(mapping = aes(x = trials, y = ..density..)) + 
  geom_line(mapping = aes(x = seq(mean - (3*sd), mean + (3*sd), length.out = 200), 
                          y = dnorm(seq(mean - (3*sd), mean + (3*sd), length.out = 200), 
                                    mean, sd)), lwd = 2, color = "blue") + 
  ggtitle("Population Distribution Curve and \nHistogram of Sample Means")

#Plot the *sampling distribution* and histogram of sample means
ggplot() + 
  geom_histogram(mapping = aes(x = trials, y = ..density..)) + 
  geom_line(mapping = aes(x = seq(mean - (3*sd/sqrt(size)), 
                                  mean + (3*sd/sqrt(size)), 
                                  length.out = 200), 
                          y = dnorm(seq(mean - (3*sd/sqrt(size)), 
                                        mean + (3*sd/sqrt(size)), 
                                        length.out = 200), 
                                    mean, sd/sqrt(size))), 
            lwd = 2, color = "blue") + xlim(mean - (3*sd), mean + (3*sd)) + 
  ggtitle("Sampling Distribution Curve and \nHistogram of Sample Means")

```

```{r normal-pop-samp-dist-questions, echo = FALSE}
quiz(
  question_radio(
    "Which of the following regarding the population and sampling distributions is true?",
    answer("The population distribution and sampling distribution are identical in the case where sample size is 1", correct = TRUE),
    answer("The population distribution and sampling distribution are always identical."),
    answer("The population distribution and sampling distribution are never identical."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Try various different values for sample `size`. What is true about the mean of the sampling distribution?",
    answer("The mean of the sampling distribution always falls near the mean of the population distribution.", correct = TRUE),
    answer("The larger the sample size, the smaller the mean of the sampling distribution."),
    answer("The larger the sample size, the larger the mean of the sampling distribution."),
    answer("The mean of the population distribution and mean of the sampling distribution are independent of one another."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Try various values of the mean, standard deviation, and sample size. What can be said about the sampling distribution?",
    answer("The sampling distribution is always nearly normal.", correct = TRUE),
    answer("The sampling distribution is always the same as the population distribution."),
    answer("The sampling distribution is always uniform."),
    answer("The sampling distribution is completely unpredictable."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Now that you've tried various values for the parameters, what can be said about the connection between sample size and the spread of the sampling distribution?",
    answer("The larger the sample size, the more narrow the sampling distribution becomes.", correct = TRUE),
    answer("The larger the sample size, the wider the sampling distribution becomes."),
    answer("The larger the sample size, the less normal the sampling distribution becomes."),
    answer("The sample size and spread of the sampling distribution are independent of one another."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```

###

**Recap:** Okay, so if a population distribution is approximately normal, then the sampling distribution is also nearly normal -- what's the big deal? The real takeaway here is that, if it reasonable to assume that data are being sampled from a population which is approximately normal, then our sample statistics provide reliable estimates for their corresponding population parameters (here, the mean). In particular, the size of our sample helps us quantify how *close* to the true population mean we might expect our sample mean to be. This is critical if we are to make population-level claims from sample-level data. Okay, so what if we can't assume that the population we are interested in follows a "nearly"-normal distribution? Do you believe in "magic"? (Disclaimer: There is actually no magic, or trickery, involved in what you are about to see -- just rock-solid mathematics. Get ready to have your mind blown!)

### A Unifromly Distributed Population

A population is said to be uniformly distributed between some minimum value `A` and a maximum value `B` if all values between `A` and `B` are equally likely to be observed when a random element of the population is observed.

###

**Uniformly Distributed Population:** Work with the following code block to explore the connection between the population distribution and sampling distribution when the population follows a uniform distribution. You'll notice in the plot on the left, that assuming a normal distribution for the population is an extremely poor choice. Use your explorations to answer the questions that follow.
```{r uniform-pop-samp-dist, exercise = TRUE, message = FALSE, warning = FALSE, fig.width = 4, fig.height = 4}
#Define the minimum value (feel free to change)
min <- 50
#Define the maximum value (feel free to change)
max <- 100
#Define the sample size (feel free to change)
size <- 1
#Define the number of samples to be taken (feel free to change)
numSamps <- 10000

#######################################
##Function to take samples, compute
##means and build sampling distribution
##Please don't edit.
#######################################
drawNunif <- function(n, times){
  vals <- rep(NA, times)
  for(i in 1:times){
    draws <- runif(n, min = min, max = max)
    vals[i] <- mean(draws)
  }
  vals
}

mean = (min + max)/2
sd = sqrt((max - min)^2/12)
#######################################
##Use the function we defined to take the samples
trials <- drawNunif(size, numSamps)

#Plot the population distribution and histogram of sample means
ggplot() + 
  geom_histogram(mapping = aes(x = trials, y = ..density..)) + 
  geom_line(mapping = aes(x = seq(mean - (3*sd), mean + (3*sd), length.out = 200), 
                          y = dnorm(seq(mean - (3*sd), mean + (3*sd), length.out = 200), 
                                    mean, sd)), 
            lwd = 2, color = "blue") + 
  ggtitle("Assumed Normal Population Distribution \nCurve and Histogram of Sample Means")

#Plot the *sampling distribution* and histogram of sample means
ggplot() + 
  geom_histogram(mapping = aes(x = trials, y = ..density..)) + 
  geom_line(mapping = aes(x = seq(mean - (3*sd/sqrt(size)), 
                                  mean + (3*sd/sqrt(size)), 
                                  length.out = 200), 
                          y = dnorm(seq(mean - (3*sd/sqrt(size)), 
                                        mean + (3*sd/sqrt(size)), 
                                        length.out = 200), 
                                    mean, sd/sqrt(size))), 
            lwd = 2, color = "blue") + xlim(mean - (3*sd), mean + (3*sd)) + 
  ggtitle("Sampling Distribution Curve and \nHistogram of Sample Means")


```

```{r uniform-pop-samp-dist-questions, echo = FALSE}
quiz(
  question_radio(
    "Which of the following regarding the sampling distributions is true?",
    answer("The sampling distribution is nearly normal as long as the sample size is at least 2", correct = TRUE),
    answer("The sampling distribution is always normal."),
    answer("The sampling distribution is never nearly normal."),
    answer("The sampling distribution always shares a common shape with the population distribution."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Try various different values for sample `size`. What is true about the mean of the sampling distribution?",
    answer("The mean of the sampling distribution always falls near the mean of the population distribution.", correct = TRUE),
    answer("The larger the sample size, the smaller the mean of the sampling distribution."),
    answer("The larger the sample size, the larger the mean of the sampling distribution."),
    answer("The mean of the population distribution and mean of the sampling distribution are independent of one another."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Try various values for the parameters, what can be said about the connection between sample size and the spread of the sampling distribution?",
    answer("The larger the sample size, the more narrow the sampling distribution becomes.", correct = TRUE),
    answer("The larger the sample size, the wider the sampling distribution becomes."),
    answer("The larger the sample size, the less normal the sampling distribution becomes."),
    answer("The sample size and spread of the sampling distribution are independent of one another."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```

###

### The Impact of Skew on the Sampling Distribution

We've seen that the sampling distribution is nearly normal for any sample size, as long as the population is nearly normally distributed. We've also seen that the sampling distribution is nearly normal for samples of size at least two (2) if our population is uniformly distributed. What if we move in a very different direction? That is, let's consider a distribution in which the population is extremely skewed -- what happens to the sampling distribution now?

###

We've encountered *skew* in our course already, and we know that it has the effect of moving the *mean* away from the center of our distribution (data). This witchcraft (read: mathematics) certainly cannot apply in the face of skewed distributions, can it?

###

**Strongly Skewed Population:** Work with the following code block to explore the connection between the population distribution and sampling distribution when the population follows a strongly skewed distribution. Use your explorations to answer the questions that follow.
```{r skew-pop-samp-dist, exercise = TRUE, message = FALSE, warning = FALSE, fig.width = 4, fig.height = 4}
#Define the first shape parameter (feel free to change)
shape <- 0.5
#Define the second shape parameter (feel free to change)
rate <- 2
#Define the sample size (feel free to change)
size <- 1
#Define the number of samples to be taken (feel free to change)
numSamps <- 10000

#######################################
##Function to take samples, compute
##means and build sampling distribution
##Please don't edit.
#######################################
drawNgamma <- function(n, times){
  vals <- rep(NA, times)
  for(i in 1:times){
    draws <- rgamma(n, shape = shape, rate = rate)
    vals[i] <- mean(draws)
  }
  vals
}

mean <- shape/rate
sd <- sqrt(shape/(rate^2))
#######################################
##Use the function we defined to take the samples
trials <- drawNgamma(size, numSamps)

#Plot the population distribution and histogram of sample means
ggplot() + 
  geom_histogram(mapping = aes(x = trials, y = ..density..)) + 
  geom_line(mapping = aes(x = seq(mean - (3*sd), mean + (3*sd), length.out = 200), 
                          y = dnorm(seq(mean - (3*sd), mean + (3*sd), length.out = 200), 
                                    mean, sd)), 
            lwd = 2, color = "blue") + 
  ggtitle("Assumed Normal Population Distribution \nCurve and Histogram of Sample Means")

#Plot the *sampling distribution* and histogram of sample means
ggplot() + 
  geom_histogram(mapping = aes(x = trials, y = ..density..)) + 
  geom_line(mapping = aes(x = seq(mean - (3*sd/sqrt(size)), 
                                  mean + (3*sd/sqrt(size)), 
                                  length.out = 200), 
                          y = dnorm(seq(mean - (3*sd/sqrt(size)), 
                                        mean + (3*sd/sqrt(size)), 
                                        length.out = 200), 
                                    mean, sd/sqrt(size))), 
            lwd = 2, color = "blue") + xlim(mean - (3*sd), mean + (3*sd)) + 
  ggtitle("Sampling Distribution Curve and \nHistogram of Sample Means")


```

```{r skewed-pop-samp-dist-questions, echo = FALSE}
quiz(
  question_radio(
    "Try running the code with samples of size 5, 10, and 20. Are the resulting sampling distributions nearly normal?",
    answer("No, the distributions are getting closer to the assumed normal sampling distribution, but still exhibit some skew in the same direction as the population distribution.", correct = TRUE),
    answer("The sampling distribution is always normal."),
    answer("No, the distributions are getting closer to the assumed normal sampling distribution, but still exhibit some skew but in the opposite direction as the population distribution."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Try samples of size 30, 50, and 100. What can be said about the resulting sampling distributions?",
    answer("The sampling distributions become closer to the assumed normal sampling distribution as sample size increases.", correct = TRUE),
    answer("There is no connection between the shape of the sampling distribution and the sample size."),
    answer("The sampling distribution always maintains the same shape as the population distribution."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
    question_radio(
    "Try various different values for the other parameters. What is true about the mean of the sampling distribution?",
    answer("The mean of the sampling distribution always falls near the mean of the population distribution.", correct = TRUE),
    answer("The larger the sample size, the smaller the mean of the sampling distribution."),
    answer("The larger the sample size, the larger the mean of the sampling distribution."),
    answer("The mean of the population distribution and mean of the sampling distribution are independent of one another."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Since you've tried various values for the parameters, what can be said about the connection between sample size and the spread of the sampling distribution?",
    answer("The larger the sample size, the more narrow the sampling distribution becomes.", correct = TRUE),
    answer("The larger the sample size, the wider the sampling distribution becomes."),
    answer("The larger the sample size, the less normal the sampling distribution becomes."),
    answer("The sample size and spread of the sampling distribution are independent of one another."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```

###

Good work through the previous sets of questions. Think about your answers to those, and try to answer the following questions about the connection between population distributions and sampling distributions in general.

```{r generic-pop-samp-dist-questions, echo = FALSE}
quiz(
  question_radio(
    "Consider a generic population distribution. What can be said about the shape of the sampling distribution?",
    answer("For large enough sample sizes, the sampling distribution is nearly normal.", correct = TRUE),
    answer("The sampling distribution is always nearly normal."),
    answer("Nothing can be said, since we don't know what the population distribution looks like."),
    answer("The sampling distribution always retains the same general shape as the population distribution."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "For a generic population distribution, what can be said about the mean of the sampling distribution?",
    answer("The mean of the sampling distribution is generally a close approximation to the mean of the population distribution.", correct = TRUE),
    answer("The mean of the sampling distribution is always less than the mean of the population distribution."),
    answer("The mean of the sampling distribution is always greater than the mean of the population distribution."),
    answer("The mean of the sampling distribution and mean of the population distribution are independent of one another."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
    question_radio(
    "For a generic population distribution, what can be said about the connection between sample size and the spread of the sampling distribution?",
    answer("The larger the sample size, the more narrow the sampling distribution.", correct = TRUE),
    answer("The larger the sample size, the wider the sampling distribution."),
    answer("The sample size and spread of the sampling distribution are independent of one another."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```

### Recap

Okay, so in all of these cases, the *mean* of the sampling distribution falls close to the *mean* of the population distribution -- we're done, right? Unfortunately, no -- the important part of all of this has to do with the *spread* of the sampling distribution. 

### 

We've been working backwards here -- we've assumed that we know the distribution of the population, and we've taken many thousands of samples from that population in order to construct the sampling distributions. This is exactly opposite of the scenario in which statistics and its methods are useful. 

###

In statistics, we don't know the population distribution -- and, we certainly don't have the ability to collect thousands of samples-worth of data. We generally collect one sample, of a fixed size, and now we want to make a claim about an unknown population. Luckily, from the experiments we've run (and from the mathematics which has been *proven* to work), we know that our sample mean falls "near" our population mean, and we can describe what we mean by "near" since it is related to the size of our sample. This is the *magic* that makes statistics work! We'll formalize it next.

## The Central Limit Theorem

###

What you just discovered through the last section and corresponding questions is what statisticians call the *Central Limit Theorem*. It is what was discussed in the *CreatureCast* video at the beginning of this workbook. This is one of the most important theorems in all of statistics and it is what will allow us to make and test claims about populations for the remainder of our course.

###

**Central Limit Theorem (simplified):** Regardless of the shape of a population distribution, for sample sizes large enough to overcome skew, the distribution of sample means (the so-called *sampling distribution*) is approximately normal. Furthermore, the mean of the sampling distribution is the same as the population mean ($\mu$), and the spread of the sampling distribution can be described by the *standard error* ($S_E$) which depends on the standard deviation of the population distribution and the size of the samples.

###

For now we'll focus on one particular application of the Central Limit Theorem to a single population. Consider $X\sim N\left(\mu,\sigma\right)$, then the Central Limit Theorem states that the distribution of sample means is as follows: $\displaystyle{\bar{X}_n\sim N\left(\mu, S_E = \sigma/\sqrt{n}\right)}$.

###

Try the following problem.

**Sample Problem:** Suppose you have 46 square foot wall which you want to cover with spray paint. The brand of spray paint you plan to use is known to have coverage which is approximately normal, with an average coverage of 10 square feet per can and a standard deviation of 1.5 square feet. Use the code block below to answer the questions that follow.
```{r spraypaint-sandbox, exercise = TRUE}

```

```{r spraypaint-questions, echo = FALSE}
quiz(
  question_radio(
    "How many square feet would each can need to cover if you wanted to use only four cans to cover the entire wall?",
    answer("10"),
    answer("10.5"),
    answer("11"),
    answer("11.5", correct = TRUE),
    answer("12"),
    allow_retry = TRUE
  ),
  question_radio(
    "What is the probability that a single can of spray paint covers at least 11.5 square feet?",
    answer("0.5"),
    answer("0.9772"),
    answer("0.1587", correct = TRUE),
    answer("0.8413"),
    answer("0.0228"),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "What is the probability that a random sample of four cans of spray paint covering an average of at least 11.5 square feet?",
    answer("0.5"),
    answer("0.9772"),
    answer("0.1587"),
    answer("0.8413"),
    answer("0.0228", correct = TRUE),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_radio(
    "Should we expect to cover the entire wall with only four cans of spray paint, or should we plan to buy 5?",
    answer("We should plan to buy five since it is unlikely (less than 5% chance) that four cans will suffice to cover the whole wall.", correct = TRUE),
    answer("We will probably be fine with four cans -- 11.5 square feet is not much more than the expected average of 10 square feet."),
    answer("Since 11.5 square feet is within one standard deviation of the expected value, it is likely that four will be enough."),
    answer("We should plan to buy five cans -- four cans will only cover 40 square feet."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```

## Submit

```{r context="server"}
learnrhash::encoder_logic(strip_output = TRUE)
```

```{r encode, echo=FALSE}
learnrhash::encoder_ui(
  ui_before = shiny::div(
    "If your instructor is asking you to submit evidence of your completed notebook using a hash code, you may generate that code below. Use the clipboard icon to ensure that you are copying the entire hash."
    )
  )
```

## Summary

**Summary:** In this workbook you were exposed to the following:

+ If $X$ is a continuous random variable, then for large enough sample sizes ($n$), the sampling distribution for $X$ with samples of size $n$ is approximately normal with mean $\mu$ (the same mean as the population mean) and *Standard Error* (spread) related to the standard deviation of the population and the sample size -- that is, the sampling distribution follows $N\left(\mu, S_E\right)$, where we can predict $S_E$.

  + If we are working with a single sample and are building a sampling distribution of sample means, then the sampling distribution is $\bar{X}_n\sim N\left(\mu, S_E = \sigma/\sqrt{n}\right)$.
  + We can use the `pnorm()` function to compute probabilities associated with the sampling distribution just as we have done previously with normally distributed population data. Just remember to use the *standard error* ($S_E$) to measure spread instead of the standard deviation ($\sigma$).

+ Remember that the presence of *skew* in a population distribution increases the required sample size in order for the Central Limit Theorem to apply. 

  + For moderate skew, samples of size 30 are usually enough to overcome the skew.
  + The more extreme the skew, the larger the sample size must be.


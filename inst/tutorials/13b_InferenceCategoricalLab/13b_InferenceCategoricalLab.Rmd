---
title: "Topic 13: Inference for Categorical Data Lab (Part B)"
tutorial:
  id: "InferenceCategoricalLab.Topic13b.AppliedStats"
  version: 1.0
output: 
  learnr::tutorial:
    progressive: TRUE
    allow_skip: TRUE
    
runtime: shiny_prerendered
description: "In this second half of the Topic 13 lab, we continue working with survey data from a 2012 WIN-Gallup poll on the global rise of atheism. The `inference()` function from the `{statsr}` package is introduced. Please use this notebook if you are on a free-tiered Posit Cloud account and have already completed the Topic 13 (Part A) notebook."
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(eval = FALSE)
#library(tidyverse)
library(ggplot2)
library(dplyr)
library(learnr)
library(gradethis)
library(statsr)

tutorial_options(exercise.timelimit = 60, exercise.checker = gradethis::grade_learnr)

load("www/atheism.RData")
rm(inference)

#knitr::opts_chunk$set(eval = FALSE)
```

## Inference for Categorical Data (Lab)

###

As a reminder, the context for this lab is as follows:

In August of 2012, news outlets ranging from the [Washington Post](http://www.washingtonpost.com/national/on-faith/poll-shows-atheism-on-the-rise-in-the-us/2012/08/13/90020fd6-e57d-11e1-9739-eef99c5fb285_story.html){target="_blank"} to the [Huffington Post](http://www.huffingtonpost.com/2012/08/14/atheism-rise-religiosity-decline-in-america_n_1777031.html){target="_blank"} ran a story about the rise of atheism in America. The source for the story was a poll that asked people, "Irrespective of whether you attend a place of worship or not, would you say you are a religious person, not a religious person or a convinced atheist?" This type of question, which asks people to classify themselves in one way or another, is common in polling and generates categorical data. In this workbook we take a look at the atheism survey and explore what's at play when making inference about population proportions using categorical data.

###

<div id="license">
This is a derivative of a product of OpenIntro that is released under a [Creative Commons Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0){target="_blank"}. The oiginal lab was written for OpenIntro by Andrew Bray and Mine &Ccedil;etinkaya-Rundel.</div>

###

In Part A of this lab, you gained familiarity with the original [WINN Gallup Survey](www/Religiosity_and_Atheism.pdf) and you also constructed a confidence interval for the proportion of Atheists in the US in 2012. You used the `inference()` function from the `{statsr}` package to do this. You also constructed two additional confidence intervals. While the `inference()` function was great at constructing the intervals, interpreting them was (and is) still our job to do.

###

In this Part B notebook, you'll get additional practice with the `inference()` function. First, however, you'll investigate the *margin of error* of a confidence interval ($\text{critical value}\cdot S_E$) more closely. In particular, you'll consider the connection between the *population proportion* and the *margin of error*. You'll also investigate the *success-failure condition* for inference on proportions more closely; investigating and comparing what the sampling distribution looks like when the condition is satisfied versus when it is not.

###

Let's check it all out!

## How does the proportion affect the margin of error?

Imagine you've set out to survey 1000 people on two questions: are you female? and are you left-handed? Since both of these sample proportions were calculated from the same sample size, they should have the same margin of error, right? Not so fast! While the margin of error does change with sample size, it is also affected by the proportion.

###

Think back to the formula for the standard error: $SE = \sqrt{p(1-p)/n}$. This is then used in the formula for the margin of error for a 95% confidence interval: $ME = 1.96\times SE = 1.96\times\sqrt{p(1-p)/n}$. Since the population proportion $p$ is in this $ME$ formula, it should make sense that the margin of error is in some way dependent on the population proportion. We can visualize this relationship by creating a plot of $ME$ vs. $p$, which is exactly what you'll do through these next few activities.

###

The code block below is pre-populated with the code necessary to make a vector `p` that is a sequence from 0 to 1 with each number separated by 0.01. The code then creates a vector of the margin of error (`me`) associated with each of these values of `p` using the familiar approximate formula ($ME = 2 \times SE$) -- note that we could also use the critical values associated with any confidence level we would like instead of 2 -- you might try this and see what happens! Lastly, we plot the two vectors against each other to reveal their relationship.

```{r me-plot, exercise = TRUE, exercise.eval = FALSE}
n <- 1000
p <- seq(0, 1, 0.01)
me <- 2 * sqrt(p * (1 - p)/n)

ggplot() + 
  geom_point(aes(x = p, y = me)) + 
  labs(
    title = "Margin of Error and Population Proportion", 
    y = "Margin of Error", 
    x = "Population Proportion"
    )
```

###

```{r p-and-me-questions, echo = FALSE}
quiz(
  question_radio(
    "Describe the relationship between the population proportion, $p$, and margin of error.",
    answer("The margin of error is small if the population proportion is near 0 or 1 but is largest for values near 0.5", correct = TRUE),
    answer("The margin of error is larger for larger values of the population proportion."),
    answer("The margin of error is smaller for larger values of the population proportion."),
    answer("There is no meaningful relationship between the population proportion and margin of error."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question_checkbox(
    "Which of the following are implications of your answer above?",
    answer("Margins of error, and therefore confidence intervals, will be widest when the population proportion to be captured is close to 0.5", correct = TRUE),
    answer("In order to estimate a population proportion to within a desired margin of error, larger sample sizes will be needed if the true population proportion is near 0.5.", correct = TRUE),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```

###

We now know that both sample size and the population parameter impact the margin of error. Often times pollsters will have requirements for the margin of error for an estimate (for example, we may be interested in estimating a President's net favorability rating to within plus or minus three percentage points). They can use these requirements, prior information, and any intuition they may have about an approximate value of the population proportion to estimate how much data they need to collect in order to satisfy their requirements on the margin of error. We can estimate required sample size using the formula below, which is just a rearrangement of the formula for margin of error ($M_E$):
$$n \geq \left(\frac{Z_{\alpha/2}}{M_E}\right)^2\cdot p\left(1 - p\right)$$
In the formula above:

+ $Z_{\alpha/2}$ is the critical value associated with the desired confidence level
+ $M_E$ is the desired margin of error
+ $p$ is an estimate for the population proportion made by using any intuition the pollster has -- if there is no viable intuition then we use $p=0.5$, a worst case scenario (as you identified earlier).

You won't use this formula right now, but you'll need it to answer one of the questions at the end of this workbook.

## Success-failure condition

The OpenIntro Statistics textbook emphasizes that you must always check conditions before making inference. For inference on proportions, the sample proportion can be assumed to be nearly normal if it is based upon a random sample of independent observations and if both $np \geq 10$ and $n(1 - p) \geq 10$. This rule of thumb is easy enough to follow, but it makes one wonder: what's so special about the number 10?

###

The short answer is: nothing. You could argue that we would be fine with 9 or that we really should be using 11. The "best" value for such a rule of thumb is, at least to some degree, arbitrary. However, when $np$ and $n(1-p)$ both reach 10 the sampling distribution is sufficiently normal to use confidence intervals and hypothesis tests that are based on that approximation.

###

We can investigate the interplay between $n$ and $p$ and the shape of the sampling distribution by using simulations. To start off, we simulate the process of drawing 5000 samples of size 1040 from a population with a true atheist proportion of 0.1. For each of the 5000 samples we compute $\hat{p}$ and then plot a histogram to visualize their distribution.

Use the code block below to carry out this experiment.

```{r sim-np, exercise = TRUE, exercise.eval = FALSE}
p <- 0.1
n <- 1040
p_hats <- rep(0, 5000)

for(i in 1:5000){
  samp <- sample(c("atheist", "non_atheist"), 
                 n, 
                 replace = TRUE, 
                 prob = c(p, 1-p))
  
  p_hats[i] <- sum(samp == "atheist")/n
}

ggplot() + 
  geom_histogram(aes(x = p_hats)) + 
  labs(title = "p = 0.1, n = 1040", 
       x = "Estimates for p") + 
  xlim(c(0, 0.18))
```

###

These commands build up the sampling distribution of $\hat{p}$ using the familiar `for` loop. You can read the sampling procedure for the first line of code inside the `for` loop as, "take a sample of size $n$ with replacement from the choices of atheist and non-atheist with probabilities $p$ and $1 - p$,respectively." The second line in the loop says, "calculate the proportion of atheists in this sample and record this value." The loop allows us to repeat this process 5,000 times to build an approximation of the sampling distribution.

Use the code block below to repeat the simulation we just ran but with `n = 400` and `p = 0.1`. Be sure to plot your result and compare it to your original simulation. What impact did lowering the number of observations have?

```{r p-dist-400-10, exercise = TRUE}

```

```{r p-dist-400-10-hint-1}
#Start with the code to run the original
#simulation. Change the sample size (n) 
#and the population proportion (p).

```

###

Now re-run the experiment again, but with `n = 1040` and `p = 0.02`. Again, think about the impact that a smaller population proportion has on the distribution of estimates for the population proportion.

```{r p-dist-1040-02, exercise = TRUE}

```

```{r p-dist-1040-02-hint-1}
#Again, start with the code to run the 
#original simulation. Change the sample 
#size (n) and the population proportion (p).

```

###

Re-run the experiment one last time, but with `n = 400` and `p = 0.02`. Compare each of your resulting distributions. How does this connect back to the assumptions for inference with categorical data?

```{r p-dist-400-02, exercise = TRUE}

```

```{r p-dist-400-02-hint-1}
#Same idea here. Update the sample size 
#and population proportion from the 
#original simulation.

```

###

```{r question-assumptions, echo = FALSE}
question_radio(
  "If you refer to Table 6 again in the WIN-Gallup report, you'll find that Australia has a sample proportion of 0.1 on a sample size of 1040, and that Ecuador has a sample proportion of 0.02 on 400 subjects. Let's suppose for this exercise that these point estimates are actually the truth. Then given the shape of their respective sampling distributions, do you think it is sensible to proceed with inference and report margin of errors, as the reports does?",
  answer("The report should not proceed with inference on Ecuador since the success-failure condition is not satisfied. The report can safely proceed with inference on Australia though.", correct = TRUE),
  answer("The report can proceed with inference on all countries. Since there were over 50,000 responses, the success-failure condition is satisfied."),
  answer("The report should not proceed with inference on either Ecuador or Australia, since the success-failure condition may not be satisfied for either country."),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
```

## On your own

The question of atheism was asked by WIN-Gallup International in a similar survey that was conducted in 2005. (We assume here that sample sizes have remained the same.) Table 4 on page 12 of the report summarizes survey results from 2005 and 2012 for 39 countries. Try answering the following questions on your own. The code blocks are necessary for answering some of the questions, but are not needed for all.

1. Answer the following two questions using the `inference()` function from `{statsr}`. As always, write out the hypotheses for any tests you conduct and outline the status of the conditions for inference.

  + Is there convincing evidence that Spain has seen a change in its atheism index between 2005 and 2012? *Hint:* Create new data sets for respondents from Spain in 2005 and 2012 (look back at how we created `us12` earlier in this workbook). Form confidence intervals for the true proportion of atheists in both years, and determine whether they overlap.
  + Is there convincing evidence that the United States has seen a change in its atheism index between 2005 and 2012?

```{r on-your-own-1, exercise = TRUE}

```

```{r on-your-own-1-hint-1}
#Start by defining spain to be a data frame
#containing only responses from Spain. You 
#don't need to filter on the year, since 
#2005 and 2012 are the only years with 
#observed responses.

```

```{r on-your-own-1-hint-2}
#Use the inference() function as earlier, but
#pass the year variable to the optional x 
#argument. This will create groups for year
#and inference() will automatically build a 
#confidence interval for the difference in 
#proportions of atheists between 2005 and 2012.
#You can ignore the warning about converting to 
#a factor.

```

2. If in fact there has been no change in the atheism index in any of the countries listed in Table 4, in how many of those countries would you expect to detect a change (at a significance level of 0.05) simply by chance? *Hint:* Look in the textbook index under Type 1 error.

```{r on-your-own-2, exercise = TRUE}

```

3. Suppose you're hired by the local government to estimate the proportion of residents that attend a religious service on a weekly basis. According to the guidelines, the estimate must have a margin of error no greater than 1% with 95% confidence. You have no idea what to expect for $p$. How many people would you have to sample to ensure that you are within the guidelines? *Hint:* Refer to your plot of the relationship between $p$ and margin of error. Do not use the data set to answer this question.

```{r on-your-own-3, exercise = TRUE}

```

```{r on-your-own-3-hint-1}
#Use the sample size formula for inference on 
#population proportions. That formula is on 
#the Standard Error Decision Tree and was also 
#included within this notebook.

```

```{r on-your-own-3-hint-2}
#Since you have no idea what proportion of 
#residents attend a religious service on a 
#weekly basis, use p = 0.5 as a worst-case
#estimate. This value of the population 
#proportion results in the largest possible 
#estimated sample size requirements.

```

## Submit

```{r context="server"}
learnrhash::encoder_logic(strip_output = TRUE)
```

```{r encode, echo=FALSE}
learnrhash::encoder_ui(
  ui_before = shiny::div(
    "If your instructor is asking you to submit evidence of your completed notebook using a hash code, you may generate that code below. Use the clipboard icon to ensure that you are copying the entire hash."
    )
  )
```

## Summary

Good work. I hope that this workbook has helped make inferential techniques a bit more intuitive for you. In particular, I hope that you better understand the connection between the margin of error and a confidence interval as well as the dependence of standard error on sample size and population proportion.

###

<div id="license">
This is lab a derivative of a product of OpenIntro that is released under a [Creative Commons Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0). The oiginal lab was written for OpenIntro by Andrew Bray and Mine &Ccedil;etinkaya-Rundel.</div>
